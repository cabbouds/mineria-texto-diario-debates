{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu May 12 23:24:54 2016\n",
    "\n",
    "@author: stuka\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import sys\n",
    "import gensim\n",
    "from string import punctuation\n",
    "from scipy.cluster.vq import kmeans,vq\n",
    "\n",
    "#Cleaning the house\n",
    "os.getcwd()\n",
    "os.chdir(\"/home/christian/Documents/ITAM_CDA/Mineria de texto/final_project/mineria-texto-diario-debates/data/raw\")\n",
    "os.listdir(\".\")\n",
    "\n",
    "path_to_raw = \"/home/christian/Documents/ITAM_CDA/Mineria de texto/final_project/mineria-texto-diario-debates/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debe venir de fuera\n",
    "\"\"\"\n",
    "Christian - pon tu path local en path_to_raw\n",
    "Mete manualmente archivos a una carpeta_christian y corre este codigo\n",
    "file_names = [f for f in os.listdir(path_to_raw+'carpeta_christian/') if f.endswith('.txt')]\n",
    "documentos =[io.open(f,'rt') for f in file_names]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "file_names = [f for f in os.listdir(path_to_raw+'raw/') if f.endswith('.txt')]\n",
    "\n",
    "documentos =[io.open(f,'rt',encoding='ISO-8859-1') for f in file_names]\n",
    "\n",
    "\n",
    "for file_name in file_names:\n",
    "    sourceEncoding = \"iso-8859-1\"\n",
    "    targetEncoding = \"utf-8\"\n",
    "    source = io.open(file_name,'rt',encoding='ISO-8859-1')\n",
    "    target = open(path_to_raw+'encoded/'+file_name, \"w\")\n",
    "    target.write(source.read().encode(targetEncoding))\n",
    "    \n",
    "documentos =[io.open(path_to_raw+'encoded/'+f,'rt') for f in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pruebas\n",
    "raw = documentos[0].read()\n",
    "\n",
    "documentos[1]\n",
    "\n",
    "dir(data[0])\n",
    "data[0].name\n",
    "#Codigo para probar stopterm\n",
    "for documento in documentos:\n",
    "    print(len(documento.read().replace(\"Honorable Asamblea:\",\"Honorable asamblea:\").split(\"Honorable asamblea:\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "#Este es el buen codigo\n",
    "\"\"\"\n",
    "documento trae un file abierto\n",
    "lo consumo a memoria con read() a un solo string\n",
    "lo parto segun keyterms = Honorable asamblea\n",
    "\"\"\"\n",
    "for documento in documentos:\n",
    "    documento_nombre = documento.name.rsplit('/',1)[1].split('.')[0]\n",
    "    raw = documento.read()\n",
    "    for i,tematica in enumerate(raw.replace(\"Honorable Asamblea:\",\"Honorable asamblea:\").split(\"Honorable asamblea:\")):\n",
    "        with io.open(path_to_raw+'tematicas/'+documento_nombre+'_'+str(i+1)+'.txt', mode=\"w\") as newfile:\n",
    "            tematica_limpia = mataAcentos(strip_punctuation(tematica.replace('\\n',' ')))\n",
    "            newfile.write(tematica_limpia)\n",
    "\n",
    "def mataAcentos(s):\n",
    "    charstosub = pd.DataFrame(zip([u'á', u'é', u'í', u'ó', u'ú',u'\"',u'“',u'”',u',',u'\\.',u'ñ',u'\\!',u'\\¡'],[u'a', u'e', u'i', u'o', u'u',u'',u'',u'',u'',u'',u'n',u'',u''])) \n",
    "    data = s.lower()\n",
    "    for row in charstosub.iterrows():\n",
    "        data = re.sub(row[1][0],row[1][1],data)\n",
    "    return data\n",
    "##Este no funciona aun\n",
    "\"\"\"\n",
    "Remover acentos y puntuacion parece no ser lo mejor\n",
    "\n",
    "\n",
    "def cleanText(corpus):\n",
    "    #punctuation = \"\"\".,?!:;(){}[]\"\"\"\n",
    "    punctuation = punctuation\n",
    "    corpus = [z.lower().replace('\\n','') for z in corpus]\n",
    "    corpus = [z.replace('<br />', ' ') for z in corpus]\n",
    "\n",
    "    #treat punctuation as individual words\n",
    "    for c in punctuation:\n",
    "        corpus = [z.replace(c, ' %s '%c) for z in corpus]\n",
    "    corpus = [z.split() for z in corpus]\n",
    "    return corpus\n",
    "\"\"\"\n",
    "\n",
    "#Esto si funciona\n",
    "def strip_punctuation(s):\n",
    "    return ''.join(c for c in s if c not in punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.doc2vec.LabeledSentence"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Christian!!!!!\n",
    "Crea una carpeta prueba y mete alli documentos de prueba para RAKE\n",
    "\"\"\"\n",
    "file_names_tematicas = [f for f in os.listdir(path_to_raw+'tematicas/') if f.endswith('.txt')]\n",
    "sentences = []\n",
    "i=0\n",
    "dicto = {}\n",
    "for doc in file_names_tematicas:\n",
    "    f = io.open(path_to_raw+'tematicas/'+doc,'rt')\n",
    "    sentences.append(gensim.models.doc2vec.LabeledSentence(f.read().split(),[\"SENT_\"+str(i+1)]))\n",
    "    dicto[\"SENT_\"+str(i+1)] = doc \n",
    "    i=i+1\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "#Pruebas\n",
    "type(sentences[0])\n",
    "#sentences[0:5]\n",
    "#print(sentences[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Modelo\n",
    "min_count = 5 # Ignora todo documento que tenga cinco palabras o menos\n",
    "size = 60 # Numero de dimensiones (tanto de las palabras como de los documentos)\n",
    "window = 10 # Cuantas palabras hacia adelante / atrás usa para trabajar\n",
    " \n",
    "model = gensim.models.doc2vec.Doc2Vec(sentences,size = size, window = window, min_count = min_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88817960753410941"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)\n",
    "len(model.vocab)\n",
    "model.similarity('pri','pan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'procesos', 0.8592633008956909)\n",
      "(u'deseos', 0.7789819240570068)\n",
      "(u'padrones', 0.7775543928146362)\n",
      "(u'razonamientos', 0.7703620195388794)\n",
      "(u'argumentos', 0.769193172454834)\n",
      "(u'aumentos', 0.7661017775535583)\n",
      "(u'escrutinios', 0.7618204951286316)\n",
      "(u'comprobantes', 0.7551262378692627)\n",
      "(u'planteamientos', 0.751236081123352)\n",
      "(u'planes', 0.7505456805229187)\n"
     ]
    }
   ],
   "source": [
    "def checa(word):\n",
    "    for i in model.most_similar(word):\n",
    "        print(i)\n",
    "        \n",
    "checa(u'fraudes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.29866070e-02,   3.13548595e-02,   6.19934313e-02,\n",
       "        -9.52612609e-02,  -1.12235203e-01,   5.33495694e-02,\n",
       "         6.36452362e-02,  -3.69031355e-02,  -2.76962798e-02,\n",
       "         1.17071301e-01,  -3.21290530e-02,  -8.86713490e-02,\n",
       "         1.30984589e-01,  -7.57516101e-02,   1.41801134e-01,\n",
       "         2.15797387e-02,  -1.91551764e-02,  -1.81097612e-01,\n",
       "        -7.17020035e-02,  -8.81236196e-02,  -1.15600675e-01,\n",
       "        -1.50600329e-01,   2.13592146e-02,  -1.69323917e-04,\n",
       "        -1.31887406e-01,   2.34025214e-02,  -4.25812528e-02,\n",
       "        -9.87764448e-02,   4.26876433e-02,  -6.25465764e-03,\n",
       "         1.34815527e-02,   1.04182675e-01,  -6.90628737e-02,\n",
       "         3.32428254e-02,   1.20900504e-01,  -7.17487112e-02,\n",
       "         3.82692963e-02,  -4.10834141e-02,  -1.75550021e-02,\n",
       "         1.77568823e-01,   1.21263348e-01,  -1.41630083e-01,\n",
       "        -1.36205465e-01,  -5.28731868e-02,  -1.47455454e-01,\n",
       "        -6.39292151e-02,   1.12984538e-01,   4.26611453e-02,\n",
       "         4.12286222e-02,   7.41293877e-02,  -6.54530749e-02,\n",
       "        -3.97740714e-02,   1.12350084e-01,   1.08701527e-01,\n",
       "        -3.71072069e-02,  -3.92855667e-02,   5.73338605e-02,\n",
       "         1.67485714e-01,   6.63426071e-02,  -1.28776014e-01], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print model.docvecs.most_similar([\"SENT_1\"])\n",
    "model.docvecs['SENT_37']\n",
    "#dir(model.docvecs)\n",
    "#model.docvecs.doctags\n",
    "#dir(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.29866070e-02,   3.13548595e-02,   6.19934313e-02,\n",
       "        -9.52612609e-02,  -1.12235203e-01,   5.33495694e-02,\n",
       "         6.36452362e-02,  -3.69031355e-02,  -2.76962798e-02,\n",
       "         1.17071301e-01,  -3.21290530e-02,  -8.86713490e-02,\n",
       "         1.30984589e-01,  -7.57516101e-02,   1.41801134e-01,\n",
       "         2.15797387e-02,  -1.91551764e-02,  -1.81097612e-01,\n",
       "        -7.17020035e-02,  -8.81236196e-02,  -1.15600675e-01,\n",
       "        -1.50600329e-01,   2.13592146e-02,  -1.69323917e-04,\n",
       "        -1.31887406e-01,   2.34025214e-02,  -4.25812528e-02,\n",
       "        -9.87764448e-02,   4.26876433e-02,  -6.25465764e-03,\n",
       "         1.34815527e-02,   1.04182675e-01,  -6.90628737e-02,\n",
       "         3.32428254e-02,   1.20900504e-01,  -7.17487112e-02,\n",
       "         3.82692963e-02,  -4.10834141e-02,  -1.75550021e-02,\n",
       "         1.77568823e-01,   1.21263348e-01,  -1.41630083e-01,\n",
       "        -1.36205465e-01,  -5.28731868e-02,  -1.47455454e-01,\n",
       "        -6.39292151e-02,   1.12984538e-01,   4.26611453e-02,\n",
       "         4.12286222e-02,   7.41293877e-02,  -6.54530749e-02,\n",
       "        -3.97740714e-02,   1.12350084e-01,   1.08701527e-01,\n",
       "        -3.71072069e-02,  -3.92855667e-02,   5.73338605e-02,\n",
       "         1.67485714e-01,   6.63426071e-02,  -1.28776014e-01], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylist = []\n",
    "tags=[]\n",
    "for doc in model.docvecs.doctags:\n",
    "    tags.append(doc)    \n",
    "    mylist.append(model.docvecs[doc])\n",
    "\n",
    "\n",
    "\n",
    "mat = np.array(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    agrupamiento = KMeans(n_clusters = i+1)\n",
    "    agrupamiento.fit(mat)\n",
    "#    mylist['clasificacion_'] = agrupamiento.labels_.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import kmeans,vq\n",
    "K = range(1,10)\n",
    "\n",
    "KM = [kmeans(mat,k) for k in K]\n",
    "centroids = [cent for (cent,var) in KM] \n",
    "avgWithinSS = [var for (cent,var) in KM] # suma de cuadrados promedio intra-cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### plot ###\n",
    "kIdx = 4\n",
    "\n",
    "# elbow curve\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(K, avgWithinSS, 'b*-')\n",
    "ax.plot(K[kIdx], avgWithinSS[kIdx], marker='o', markersize=12, \n",
    "    markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Numero de clusters')\n",
    "plt.ylabel('Suma de cuadrados promedio intra-cluster')\n",
    "plt.title('Criterio del codo para K-Medias')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in len(range(10)):\n",
    "    \n",
    "X_suma = documentos_suma[['vector1','vector2']].as_matrix()\n",
    "agrupamiento = KMeans(n_clusters = i)\n",
    "agrupamiento.fit(X_suma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for doc in model.doc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
